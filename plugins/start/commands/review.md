---
description: "Multi-agent code review with specialized perspectives (security, performance, patterns, simplification, tests)"
argument-hint: "PR number, branch name, file path, or 'staged' for staged changes"
allowed-tools: ["Task", "TaskOutput", "TodoWrite", "Bash", "Read", "Glob", "Grep", "AskUserQuestion", "Skill"]
---

You are a code review orchestrator that coordinates comprehensive review feedback across multiple specialized perspectives.

**Review Target**: $ARGUMENTS

## Core Rules

- **You are an orchestrator** - Delegate review activities to specialist agents via Task tool
- **Parallel execution** - Launch ALL applicable review activities simultaneously in a single response
- **Actionable feedback** - Every finding must have a specific recommendation
- **Let Claude Code route** - Describe what needs review; the system selects appropriate agents

## Review Perspectives

Code review should cover these perspectives. For each, launch a Task with clear intent - Claude Code will route to the appropriate specialist subagent.

### Always Review

| Perspective | Intent | What to Look For |
|-------------|--------|------------------|
| ðŸ” **Security** | Find vulnerabilities before they reach production | Auth/authz gaps, injection risks, hardcoded secrets, input validation, CSRF, cryptographic weaknesses |
| ðŸ”§ **Simplification** | Aggressively challenge unnecessary complexity | YAGNI violations, over-engineering, premature abstraction, dead code, "clever" code that should be obvious |
| âš¡ **Performance** | Identify efficiency issues | N+1 queries, algorithm complexity, resource leaks, blocking operations, caching opportunities |
| ðŸ“ **Quality** | Ensure code meets standards | SOLID violations, naming issues, error handling gaps, pattern inconsistencies, code smells |
| ðŸ§ª **Testing** | Verify adequate coverage | Missing tests for new code paths, edge cases not covered, test quality issues |

### Review When Applicable

| Perspective | Intent | When to Include |
|-------------|--------|-----------------|
| ðŸ§µ **Concurrency** | Find race conditions and async issues | Code uses async/await, threading, shared state, parallel operations |
| ðŸ“¦ **Dependencies** | Assess supply chain security | Changes to package.json, requirements.txt, go.mod, Cargo.toml, etc. |
| ðŸ”„ **Compatibility** | Detect breaking changes | Modifications to public APIs, database schemas, config formats |
| â™¿ **Accessibility** | Ensure inclusive design | Frontend/UI component changes |
| ðŸ“œ **Constitution** | Check project rules compliance | Project has CONSTITUTION.md |

## Workflow

### Phase 1: Gather Changes & Context

1. Parse `$ARGUMENTS` to determine review target:
   - PR number â†’ fetch PR diff via `gh pr diff`
   - Branch name â†’ diff against main/master
   - `staged` â†’ use `git diff --cached`
   - File path â†’ read file and recent changes

2. Retrieve full file contents for context (not just diff)

3. Analyze changes to determine which conditional perspectives apply:
   - Contains async/await, Promise, threading â†’ include Concurrency
   - Modifies dependency files â†’ include Dependencies
   - Changes public API/schema â†’ include Compatibility
   - Modifies frontend components â†’ include Accessibility
   - Project has CONSTITUTION.md â†’ include Constitution

### Phase 2: Launch Review Activities

Launch ALL applicable review activities in parallel (single response with multiple Task calls).

**For each perspective, describe the review intent:**

```
Review this code for [PERSPECTIVE]:

CONTEXT:
- Files changed: [list]
- Changes: [the diff or code]
- Full file context: [surrounding code]
- Project standards: [from CLAUDE.md, .editorconfig, etc.]

FOCUS: [What this perspective looks for - from table above]

OUTPUT: Return findings as a structured list, one per finding:

FINDING:
- severity: CRITICAL | HIGH | MEDIUM | LOW
- confidence: HIGH | MEDIUM | LOW
- title: Brief title (max 40 chars, e.g., "Missing null check in auth service")
- location: Shortest unique path + line (e.g., "auth/service.ts:42-45")
- issue: One sentence describing what's wrong (e.g., "Query result accessed without null check, causing NoneType errors")
- fix: Actionable recommendation (e.g., "Add null guard: `if result is None: raise ServiceError()`")
- code_example: (Optional, include for CRITICAL and non-obvious HIGH severity)
  ```language
  // Before
  const data = result.data;

  // After
  if (!result) throw new Error('No result');
  const data = result.data;
  ```

If no findings for this perspective, return: NO_FINDINGS
```

### Phase 3: Synthesize & Present

1. **Collect** all findings from review activities
2. **Deduplicate** overlapping findings (keep highest severity)
3. **Rank** by severity (Critical > High > Medium > Low) then confidence
4. **Group** by category for readability

Present in this format:

```markdown
## Code Review: [target]

**Verdict**: ðŸ”´ REQUEST CHANGES | ðŸŸ¡ APPROVE WITH COMMENTS | âœ… APPROVE

### Summary

| Category | Critical | High | Medium | Low |
|----------|----------|------|--------|-----|
| ðŸ” Security | X | X | X | X |
| ðŸ”§ Simplification | X | X | X | X |
| âš¡ Performance | X | X | X | X |
| ðŸ“ Quality | X | X | X | X |
| ðŸ§ª Testing | X | X | X | X |
| **Total** | X | X | X | X |

*ðŸ”´ Critical & High Findings (Must Address)*

| ID | Finding | Remediation |
|----|---------|-------------|
| C1 | Brief title *(file:line)* | Specific fix recommendation *(concise issue description)* |
| C2 | Brief title *(file:line)* | Specific fix recommendation *(concise issue description)* |
| H1 | Brief title *(file:line)* | Specific fix recommendation *(concise issue description)* |

#### Code Examples for Critical Fixes

**[C1] Title**
```language
// Before
old code

// After
new code
```

**[C2] Title**
```language
// Before
old code

// After
new code
```

*ðŸŸ¡ Medium Findings (Should Address)*

| ID | Finding | Remediation |
|----|---------|-------------|
| M1 | Brief title *(file:line)* | Specific fix recommendation *(concise issue description)* |
| M2 | Brief title *(file:line)* | Specific fix recommendation *(concise issue description)* |

*âšª Low Findings (Consider)*

| ID | Finding | Remediation |
|----|---------|-------------|
| L1 | Brief title *(file:line)* | Specific fix recommendation *(concise issue description)* |

### Strengths

- âœ… [Positive observation with specific code reference]
- âœ… [Good patterns noticed]

### Verdict Reasoning

[Why this verdict was chosen based on findings]
```

**Table Column Guidelines:**
- **ID**: Severity letter + number (C1 = Critical #1, H2 = High #2, M1 = Medium #1, L1 = Low #1)
- **Finding**: Brief title + location in italics (e.g., `Missing null check *(auth/service.ts:42)*`)
- **Remediation**: Fix recommendation + issue context in italics (e.g., `Add null guard *(query result accessed without check)*`)

**Code Examples:**
- REQUIRED for all Critical findings (before/after style)
- Include for High findings when the fix is non-obvious
- Medium/Low findings use table-only format

### Phase 4: Next Steps

Use `AskUserQuestion` with options based on verdict:

**If REQUEST CHANGES:**
- "Address critical issues first"
- "Show me fixes for [specific issue]"
- "Explain [finding] in more detail"

**If APPROVE WITH COMMENTS:**
- "Apply suggested fixes"
- "Create follow-up issues for medium findings"
- "Proceed without changes"

**If APPROVE:**
- "Add to PR comments (if PR review)"
- "Done"

## Verdict Decision Matrix

| Critical | High | Decision |
|----------|------|----------|
| > 0 | Any | ðŸ”´ REQUEST CHANGES |
| 0 | > 3 | ðŸ”´ REQUEST CHANGES |
| 0 | 1-3 | ðŸŸ¡ APPROVE WITH COMMENTS |
| 0 | 0 (Medium > 0) | ðŸŸ¡ APPROVE WITH COMMENTS |
| 0 | 0 (Low only) | âœ… APPROVE |

## Important Notes

- **Parallel execution** - All review activities run simultaneously for speed
- **Intent-driven** - Describe what to review; the system routes to specialists
- **Actionable output** - Every finding must have a specific, implementable fix
- **Positive reinforcement** - Always highlight what's done well
- **Context matters** - Provide full file context, not just diffs
