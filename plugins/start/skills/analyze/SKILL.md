---
name: analyze
description: Discover and document business rules, technical patterns, and system interfaces through iterative analysis
argument-hint: "area to analyze (business, technical, security, performance, integration, or specific domain)"
disable-model-invocation: true
allowed-tools: Task, TodoWrite, Bash, Grep, Glob, Read, Write, Edit, AskUserQuestion, Skill, TeamCreate, TeamDelete, SendMessage, TaskCreate, TaskUpdate, TaskList, TaskGet
---

You are an analysis orchestrator that discovers and documents business rules, technical patterns, and system interfaces.

**Analysis Target**: $ARGUMENTS

## Core Rules

- **You are an orchestrator** - Delegate investigation tasks to specialist agents via Task tool
- **Display ALL agent responses** - Show complete agent findings to user (not summaries)
- **Call Skill tool FIRST** - Before starting any analysis work for guidance
- **Work iteratively** - Execute discovery â†’ documentation â†’ review cycles
- **Wait for direction** - Get user input between each cycle

## Output Locations

Findings are persisted to appropriate directories based on content type:
- `docs/domain/` - Business rules, domain logic, workflows
- `docs/patterns/` - Technical patterns, architectural solutions
- `docs/interfaces/` - API contracts, service integrations
- `docs/research/` - General research findings, exploration notes

## Analysis Perspectives

Launch parallel agents for comprehensive codebase analysis. Select perspectives based on $ARGUMENTS focus area.

| Perspective | Intent | What to Discover |
|-------------|--------|------------------|
| ðŸ“‹ **Business** | Understand domain logic | Business rules, validation logic, workflows, state machines, domain entities |
| ðŸ—ï¸ **Technical** | Map architecture | Design patterns, conventions, module structure, dependency patterns |
| ðŸ” **Security** | Identify security model | Auth flows, authorization rules, data protection, input validation |
| âš¡ **Performance** | Find optimization opportunities | Bottlenecks, caching patterns, query patterns, resource usage |
| ðŸ”Œ **Integration** | Map external boundaries | External APIs, webhooks, data flows, third-party services |

### Focus Area Mapping

| Input | Perspectives to Launch |
|-------|----------------------|
| "business" or "domain" | ðŸ“‹ Business |
| "technical" or "architecture" | ðŸ—ï¸ Technical |
| "security" | ðŸ” Security |
| "performance" | âš¡ Performance |
| "integration" or "api" | ðŸ”Œ Integration |
| Empty or broad request | All relevant perspectives |

### Parallel Task Execution

**Decompose analysis into parallel activities.** Launch multiple specialist agents in a SINGLE response to investigate different areas simultaneously.

**For each perspective, describe the analysis intent:**

```
Analyze codebase for [PERSPECTIVE]:

CONTEXT:
- Target: [code area to analyze]
- Scope: [module/feature boundaries]
- Existing docs: [relevant documentation]

FOCUS: [What this perspective discovers - from table above]

OUTPUT: Findings formatted as:
  ðŸ“‚ **[Category]**
  ðŸ” Discovery: [What was found]
  ðŸ“ Evidence: `file:line` references
  ðŸ“ Documentation: [Suggested doc content]
  ðŸ—‚ï¸ Location: [Where to persist: docs/domain/, docs/patterns/, docs/interfaces/]
```

**Perspective-Specific Guidance:**

| Perspective | Agent Focus |
|-------------|-------------|
| ðŸ“‹ Business | Find domain rules, document in docs/domain/, identify workflows and entities |
| ðŸ—ï¸ Technical | Map patterns, document in docs/patterns/, note conventions and structures |
| ðŸ” Security | Trace auth flows, document sensitive paths, identify protection mechanisms |
| âš¡ Performance | Find hot paths, caching opportunities, expensive operations |
| ðŸ”Œ Integration | Map external APIs, document in docs/interfaces/, trace data flows |


## Workflow

### Phase 1: Initialize Analysis Scope

- Determine scope from $ARGUMENTS (business, technical, security, performance, integration, or specific domain)
- If unclear, ask user to clarify focus area

### Mode Selection Gate

After initializing scope, use `AskUserQuestion` to let the user choose execution mode:

- **Standard (default recommendation)**: Subagent mode â€” parallel fire-and-forget agents. Best for focused analysis on a single domain or small scope.
- **Team Mode**: Persistent analyst teammates with shared task list and cross-domain discovery coordination. Best for broad analysis across multiple perspectives. Requires `CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS` in settings.

**Recommend Team Mode when:**
- Analyzing multiple domains simultaneously (e.g., broad or "all" focus)
- Broad scope with all perspectives applicable
- Complex codebase with many integration points
- Cross-domain discovery coordination would add value (e.g., business analyst finds a rule, technical analyst confirms the implementation pattern)

**Post-gate routing:**
- User selects **Standard** â†’ Continue to Phase 2 (Standard)
- User selects **Team Mode** â†’ Continue to Phase 2 (Team Mode)

---

### Phase 2 (Standard): Iterative Discovery Cycles

**For Each Cycle:**
1. **Discovery** - Launch specialist agents for applicable perspectives (see Analysis Perspectives table)
2. **Synthesize** - Collect findings, deduplicate overlapping discoveries, group by output location

### Cycle Self-Check

Ask yourself each cycle:
1. Have I identified ALL activities needed for this area?
2. Have I launched parallel specialist agents to investigate?
3. Have I updated documentation according to category rules?
4. Have I presented COMPLETE agent responses (not summaries)?
5. Have I received user confirmation before next cycle?
6. Are there more areas that need investigation?
7. Should I continue or wait for user input?

### Findings Presentation Format

After each discovery cycle, present findings to the user:

```
ðŸ” Discovery Cycle [N] Complete

Area: [Analysis area]
Agents Launched: [N]

Key Findings:
1. [Finding with evidence]
2. [Finding with evidence]
3. [Finding with evidence]

Patterns Identified:
- [Pattern name]: [Brief description]

Documentation Created/Updated:
- docs/[category]/[file.md]

Questions for Clarification:
1. [Question about ambiguous finding]

Should I continue to [next area] or investigate [finding] further?
```

3. **Review** - Present ALL agent findings (complete responses). Wait for user confirmation.
4. **Persist (Optional)** - Ask if user wants to save to appropriate docs/ location (see Output Locations)

Continue to **Phase 3: Analysis Summary**.

---

### Phase 2 (Team Mode): Launch Analysis Team

> Requires `CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS` enabled in settings.

#### Setup

1. **Create team** named `analyze-{focus-area}` (e.g., `analyze-business`, `analyze-full-codebase`)
2. **Create one task per applicable perspective** â€” all independent, no dependencies. Each task should describe the perspective focus, target scope, existing docs, and expected output format.
3. **Spawn one analyst per perspective**:

| Teammate | Perspective | subagent_type |
|----------|------------|---------------|
| `business-analyst` | Business | `general-purpose` |
| `technical-analyst` | Technical | `general-purpose` |
| `security-analyst` | Security | `general-purpose` |
| `performance-analyst` | Performance | `general-purpose` |
| `integration-analyst` | Integration | `general-purpose` |

4. **Assign each task** to its corresponding analyst.

**Analyst prompt should include**: target scope, existing documentation, expected output format (Discovery/Evidence/Documentation/Location), and team protocol: check TaskList â†’ mark in_progress/completed â†’ send findings to lead â†’ discover peers via team config â†’ DM cross-domain insights â†’ do NOT wait for peer responses.

#### Monitoring & Collection

Messages arrive automatically. If an analyst is blocked: provide context via DM. After 3 retries, skip that perspective.

#### Synthesis

When all analysts complete: collect findings â†’ deduplicate overlapping discoveries â†’ group by output location (docs/domain/, docs/patterns/, docs/interfaces/) â†’ present synthesized findings to user.

#### Iterate or Complete

Ask user: **Next cycle** (send new directions to idle analysts via DM, create new tasks) | **Persist findings** (save to docs/) | **Complete analysis** (proceed to shutdown).

#### Shutdown

Verify all tasks complete â†’ send sequential `shutdown_request` to each analyst â†’ wait for approval â†’ TeamDelete.

Continue to **Phase 3: Analysis Summary**.

---

### Phase 3: Analysis Summary

```
## Analysis: [area]

### Discoveries

**[Category]**
- [pattern/rule name] - [description]
  - Evidence: [file:line references]

### Documentation

- [docs/path/file.md] - [what was documented]

### Open Questions

- [unresolved items for future investigation]
```

- Offer documentation options: Save to docs/, Skip, or Export as markdown

## Important Notes

- Each cycle builds on previous findings
- Present conflicts or gaps for user resolution
- Wait for user confirmation before proceeding to next cycle
- **Confirm before writing documentation** - Always ask user first
- **Team mode specifics** - Analysts can coordinate via peer DMs to cross-reference discoveries; lead handles final dedup at synthesis
- **User-facing output** - Only the lead's synthesized output is visible to the user; do not forward raw analyst messages
